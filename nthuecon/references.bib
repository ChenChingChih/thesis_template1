
@book{allaBeginningAnomalyDetection2019,
	title = {Beginning {Anomaly} {Detection} {Using} {Python}-{Based} {Deep} {Learning}},
	language = {en-us},
	publisher = {Springer},
	author = {Alla, Sridhar and Adari, Suman Kalyan},
	year = {2019}
}

@article{baiEmpiricalEvaluationGeneric2018,
	title = {An empirical evaluation of generic convolutional and recurrent networks for sequence modeling},
	language = {en-us},
	journal = {arXiv preprint arXiv:1803.01271},
	author = {Bai, Shaojie and Kolter, J. Zico and Koltun, Vladlen},
	year = {2018},
	file = {Full Text:C\:\\Users\\ChingChih\\Zotero\\storage\\VMDHYUC8\\Bai 等。 - 2018 - An empirical evaluation of generic convolutional a.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\YKY9K9XR\\1803.html:text/html}
}

@book{ghyselsAppliedEconomicForecasting2018,
	title = {Applied economic forecasting using time series methods},
	language = {en-us},
	publisher = {Oxford University Press},
	author = {Ghysels, Eric and Marcellino, Massimiliano},
	year = {2018},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\6UIUYH2L\\books.html:text/html}
}

@book{subramanianDeepLearningPyTorch2018,
	title = {Deep {Learning} with {PyTorch}: {A} practical approach to building neural network models using {PyTorch}},
	isbn = {978-1-78862-607-1},
	shorttitle = {Deep {Learning} with {PyTorch}},
	abstract = {Build neural network models in text, vision and advanced analytics using PyTorchKey FeaturesLearn PyTorch for implementing cutting-edge deep learning algorithms.Train your neural networks for higher speed and flexibility and learn how to implement them in various scenarios;Cover various advanced neural network architecture such as ResNet, Inception, DenseNet and more with practical examples;Book DescriptionDeep learning powers the most intelligent systems in the world, such as Google Voice, Siri, and Alexa. Advancements in powerful hardware, such as GPUs, software frameworks such as PyTorch, Keras, Tensorflow, and CNTK along with the availability of big data have made it easier to implement solutions to problems in the areas of text, vision, and advanced analytics. This book will get you up and running with one of the most cutting-edge deep learning libraries—PyTorch. PyTorch is grabbing the attention of deep learning researchers and data science professionals due to its accessibility, efficiency and being more native to Python way of development. You'll start off by installing PyTorch, then quickly move on to learn various fundamental blocks that power modern deep learning. You will also learn how to use CNN, RNN, LSTM and other networks to solve real-world problems. This book explains the concepts of various state-of-the-art deep learning architectures, such as ResNet, DenseNet, Inception, and Seq2Seq, without diving deep into the math behind them. You will also learn about GPU computing during the course of the book. You will see how to train a model with PyTorch and dive into complex neural networks such as generative networks for producing text and images. By the end of the book, you'll be able to implement deep learning applications in PyTorch with ease.What you will learnUse PyTorch for GPU-accelerated tensor computationsBuild custom datasets and data loaders for images and test the models using torchvision and torchtextBuild an image classifier by implementing CNN architectures using PyTorchBuild systems that do text classification and language modeling using RNN, LSTM, and GRULearn advanced CNN architectures such as ResNet, Inception, Densenet, and learn how to use them for transfer learningLearn how to mix multiple models for a powerful ensemble modelGenerate new images using GAN’s and generate artistic images using style transferWho this book is forThis book is for machine learning engineers, data analysts, data scientists interested in deep learning and are looking to explore implementing advanced algorithms in PyTorch. Some knowledge of machine learning is helpful but not a mandatory need. Working knowledge of Python programming is expected.},
	language = {en-us},
	publisher = {Packt Publishing Ltd},
	author = {Subramanian, Vishnu},
	month = feb,
	year = {2018},
	note = {Google-Books-ID: DOlODwAAQBAJ},
	keywords = {Computers / Data Processing, Computers / Databases / General, Computers / Intelligence (AI) \& Semantics, Computers / Neural Networks}
}

@techreport{hallMacroeconomicIndicatorForecasting2017,
	title = {Macroeconomic {Indicator} {Forecasting} with {Deep} {Neural} {Networks}},
	language = {en-us},
	urldate = {2020-09-29},
	institution = {Federal Reserve Bank of Kansas City},
	author = {Hall, Aaron Smalter and Cook, Thomas R.},
	month = sep,
	year = {2017},
	file = {Macroeconomic Indicator Forecasting with Deep Neural Networks by Aaron Smalter Hall, Thomas R. Cook \:\: SSRN:C\:\\Users\\ChingChih\\Zotero\\storage\\D46LERUN\\papers.html:text/html}
}

@article{merityRegularizingOptimizingLSTM2017,
	title = {Regularizing and {Optimizing} {LSTM} {Language} {Models}},
	url = {http://arxiv.org/abs/1708.02182},
	abstract = {Recurrent neural networks (RNNs), such as long short-term memory networks (LSTMs), serve as a fundamental building block for many sequence learning tasks, including machine translation, language modeling, and question answering. In this paper, we consider the specific problem of word-level language modeling and investigate strategies for regularizing and optimizing LSTM-based models. We propose the weight-dropped LSTM which uses DropConnect on hidden-to-hidden weights as a form of recurrent regularization. Further, we introduce NT-ASGD, a variant of the averaged stochastic gradient method, wherein the averaging trigger is determined using a non-monotonic condition as opposed to being tuned by the user. Using these and other regularization strategies, we achieve state-of-the-art word level perplexities on two data sets: 57.3 on Penn Treebank and 65.8 on WikiText-2. In exploring the effectiveness of a neural cache in conjunction with our proposed model, we achieve an even lower state-of-the-art perplexity of 52.8 on Penn Treebank and 52.0 on WikiText-2.},
	language = {en-us},
	urldate = {2020-09-29},
	journal = {arXiv:1708.02182 [cs]},
	author = {Merity, Stephen and Keskar, Nitish Shirish and Socher, Richard},
	month = aug,
	year = {2017},
	note = {arXiv: 1708.02182},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	file = {arXiv Fulltext PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\3ALEUR6U\\Merity 等。 - 2017 - Regularizing and Optimizing LSTM Language Models.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\SUJWBSQG\\1708.html:text/html}
}

@article{dieboldPresentFutureMacroeconomic1998,
	title = {The {Past}, {Present}, and {Future} of {Macroeconomic} {Forecasting}},
	volume = {12},
	issn = {0895-3309},
	doi = {10.1257/jep.12.2.175},
	abstract = {Broadly defined, macroeconomic forecasting is alive and well. Nonstructural forecasting, which is based largely on reduced-form correlations, has always been well and continues to improve. Structural forecasting, which aligns itself with economic theory and hence rises and falls with theory, receded following the decline of Keynesian theory. In recent years, however, powerful new dynamic stochastic general equilibrium theory has been developed and structural macroeconomic forecasting is poised for resurgence.},
	language = {en},
	number = {2},
	urldate = {2020-11-22},
	journal = {Journal of Economic Perspectives},
	author = {Diebold, Francis X.},
	month = jun,
	year = {1998},
	keywords = {Forecasting and Other Model Applications, General Aggregative Models: Forecasting and Simulation},
	pages = {175--192},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\PZAH6NP4\\articles.html:text/html;全文:C\:\\Users\\ChingChih\\Zotero\\storage\\4MR9ZWCD\\Diebold - 1998 - The Past, Present, and Future of Macroeconomic For.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\DQUYWR38\\articles.html:text/html}
}

@article{lucasEconometricPolicyEvaluation1976,
	title = {Econometric policy evaluation: {A} critique},
	volume = {1},
	issn = {0167-2231},
	shorttitle = {Econometric policy evaluation},
	doi = {10.1016/S0167-2231(76)80003-6},
	language = {en},
	urldate = {2020-11-22},
	journal = {Carnegie-Rochester Conference Series on Public Policy},
	author = {Lucas, Robert E.},
	month = jan,
	year = {1976},
	pages = {19--46},
	file = {送出的版本:C\:\\Users\\ChingChih\\Zotero\\storage\\4R5U37ZE\\Lucas - 1976 - Econometric policy evaluation A critique.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\EPFLG24S\\S0167223176800036.html:text/html}
}

@article{montgomeryForecastingUnemploymentRate1998,
	title = {Forecasting the {U}.{S}. {Unemployment} {Rate}},
	volume = {93},
	issn = {0162-1459},
	doi = {10.2307/2670094},
	abstract = {This article presents a comparison of forecasting performance for a variety of linear and nonlinear time series models using the U.S. unemployment rate. Our main emphases are on measuring forecasting performance during economic expansions and contractions by exploiting the asymmetric cyclical behavior of unemployment numbers, on building vector models that incorporate initial jobless claims as a leading indicator, and on utilizing additional information provided by the monthly rate for forecasting the quarterly rate. Comparisons are also made with the consensus forecasts from the Survey of Professional Forecasters. In addition, the forecasts of nonlinear models are combined with the consensus forecasts. The results show that significant improvements in forecasting accuracy can be obtained over existing methods.},
	number = {442},
	urldate = {2020-11-22},
	journal = {Journal of the American Statistical Association},
	author = {Montgomery, Alan L. and Zarnowitz, Victor and Tsay, Ruey S. and Tiao, George C.},
	year = {1998},
	pages = {478--493}
}

@article{tsayTimeSeriesForecasting,
	title = {Time {Series} and {Forecasting}: {Brief} {History} and {Future} {Research}},
	language = {en},
	journal = {Statistics in the Social Sciences},
	author = {Tsay, Ruey S},
	pages = {7},
	file = {Tsay - Time Series and Forecasting Brief History and Fut.pdf:C\:\\Users\\ChingChih\\Zotero\\storage\\YU3QHTDC\\Tsay - Time Series and Forecasting Brief History and Fut.pdf:application/pdf}
}

@article{katrisPredictionUnemploymentRates2020,
	title = {Prediction of {Unemployment} {Rates} with {Time} {Series} and {Machine} {Learning} {Techniques}},
	volume = {55},
	issn = {1572-9974},
	url = {https://doi.org/10.1007/s10614-019-09908-9},
	doi = {10.1007/s10614-019-09908-9},
	abstract = {In this paper, are explored and analyzed time series and machine learning models for prediction of unemployment in several countries (Med, Baltic, Balkan, Nordic, Benelux) for different forecasting horizons. FARIMA is a suitable model when long memory exists in a time series and has been applied successfully for predicting unemployment. To overcome the potential issue of heteroskedasticity, we explore whether FARIMA models with GARCH errors achieve more accurate results. To further improve forecasting accuracy, we consider models with non-normal errors. The above models however cannot take into account the non-linearity of the data and due to this fact, we employ three machine learning techniques to forecast unemployment rates, i.e. fully connected feed forward neural networks, support vector regression and multivariate adaptive regression splines. ARIMA and Holt-Winters are considered as benchmark models. Finally, the effects of different forecasting horizons and different geographic locations in terms of forecasting accuracy of the models are explored.},
	language = {en},
	number = {2},
	urldate = {2020-11-24},
	journal = {Computational Economics},
	author = {Katris, Christos},
	month = feb,
	year = {2020},
	pages = {673--706}
}

@misc{AmazonComTime,
	title = {Amazon.com：{Time} {Series} {Analysis} : {Univariate} and {Multivariate} {Methods} (2nd {Edition}) (9780321322166): {Wei}, {William} {W}. {S}.: {Books}},
	url = {https://www.amazon.com/Time-Analysis-Univariate-Multivariate-Methods/dp/0321322169},
	urldate = {2020-11-25},
	file = {Amazon.com：Time Series Analysis \: Univariate and Multivariate Methods (2nd Edition) (9780321322166)\: Wei, William W. S.\: Books:C\:\\Users\\ChingChih\\Zotero\\storage\\XTAAF54D\\0321322169.html:text/html}
}

@book{weiTimeSeriesAnalysis2005,
	address = {Boston},
	title = {Time {Series} {Analysis} : {Univariate} and {Multivariate} {Methods}},
	isbn = {978-0-321-32216-6},
	shorttitle = {Time {Series} {Analysis}},
	abstract = {With its broad coverage of methodology, this comprehensive book is a useful learning and reference tool for those in applied sciences where analysis and research of time series is useful. Its plentiful examples show the operational details and purpose of a variety of univariate and multivariate time series methods. Numerous figures, tables and real-life time series data sets illustrate the models and methods useful for analyzing, modeling, and forecasting data collected sequentially in time. The text also offers a balanced treatment between theory and applications.      Overview. Fundamental Concepts. Stationary Time Series Models. Nonstationary Time Series Models. Forecasting. Model Identification. Parameter Estimation, Diagnostic Checking, and Model Selection. Seasonal Time Series Models. Testing for a Unit Root. Intervention Analysis and Outlier Detection. Fourier Analysis. Spectral Theory of Stationary Processes. Estimation of the Spectrum. Transfer Function Models. Time Series Regression and GARCH Models. Vector Time Series Models. More on Vector Time Series. State Space Models and the Kalman Filter. Long Memory and Nonlinear Processes. Aggregation and Systematic Sampling in Time Series.     For all readers interested in time series analysis.},
	author = {Wei, William W. S.},
	month = jul,
	year = {2005}
}

@article{hyndmanAutomaticTimeSeries2008,
	title = {Automatic {Time} {Series} {Forecasting}: {The} forecast {Package} for {R}},
	volume = {27},
	copyright = {Copyright (c) 2007 Rob J. Hyndman, Yeasmin Khandakar},
	issn = {1548-7660},
	shorttitle = {Automatic {Time} {Series} {Forecasting}},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v027i03},
	doi = {10.18637/jss.v027.i03},
	language = {en},
	number = {1},
	urldate = {2020-11-26},
	journal = {Journal of Statistical Software},
	author = {Hyndman, Rob J. and Khandakar, Yeasmin},
	month = jul,
	year = {2008},
	note = {Number: 1},
	pages = {1--22},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\7KCATL3N\\v027i03.html:text/html;全文:C\:\\Users\\ChingChih\\Zotero\\storage\\BUBTS2HR\\Hyndman 與 Khandakar - 2008 - Automatic Time Series Forecasting The forecast Pa.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\66F349AK\\v027i03.html:text/html}
}

@article{leeTestingNeglectedNonlinearity1993,
	title = {Testing for neglected nonlinearity in time series models: {A} comparison of neural network methods and alternative tests},
	volume = {56},
	issn = {0304-4076},
	number = {3},
	urldate = {2020-11-26},
	journal = {Journal of Econometrics},
	author = {Lee, Tae Hwy and White, Halbert and Granger, Clive},
	year = {1993},
	pages = {269--290},
	file = {RePEc Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\2L4992HD\\v_3a56_3ay_3a1993_3ai_3a3_3ap_3a269-290.html:text/html}
}

@misc{POWERNEURALNETWORK,
	title = {{POWER} {OF} {THE} {NEURAL} {NETWORK} {LINEARITY} {TEST} - {Teräsvirta} - 1993 - {Journal} of {Time} {Series} {Analysis} - {Wiley} {Online} {Library}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9892.1993.tb00139.x},
	urldate = {2020-11-26},
	file = {POWER OF THE NEURAL NETWORK LINEARITY TEST - Teräsvirta - 1993 - Journal of Time Series Analysis - Wiley Online Library:C\:\\Users\\ChingChih\\Zotero\\storage\\JG32GRAJ\\j.1467-9892.1993.tb00139.html:text/html}
}

@article{hochreiterLongShortTermMemory1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2020-11-27},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	note = {Publisher: MIT Press},
	pages = {1735--1780},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\LMIXJI2D\\neco.1997.9.8.html:text/html}
}

@article{waibelPhonemeRecognitionUsing1989,
	title = {Phoneme recognition using time-delay neural networks},
	url = {https://ieeexplore.ieee.org/document/21701},
	urldate = {2020-11-27},
	journal = {IEEE Transactions on Acoustics, Speech, and Signal Processing},
	author = {Waibel, Alex and Hanazawa, Toshiyuki and Hinton, Geoffrey and Shikano, Kiyohiro and Lang, K. J.},
	year = {1989},
	file = {Phoneme recognition using time-delay neural networks - IEEE Journals & Magazine:C\:\\Users\\ChingChih\\Zotero\\storage\\EMQ5VKPD\\21701.html:text/html}
}

@article{heDeepResidualLearning2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	urldate = {2020-11-28},
	journal = {arXiv:1512.03385 [cs]},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {Comment: Tech report},
	file = {arXiv Fulltext PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\47R69U37\\He 等。 - 2015 - Deep Residual Learning for Image Recognition.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\9HZSC4H2\\1512.html:text/html}
}

@misc{170802182Regularizing,
	title = {[1708.02182] {Regularizing} and {Optimizing} {LSTM} {Language} {Models}},
	url = {https://arxiv.org/abs/1708.02182},
	urldate = {2020-11-28},
	file = {[1708.02182] Regularizing and Optimizing LSTM Language Models:C\:\\Users\\ChingChih\\Zotero\\storage\\IL5BF7HS\\1708.html:text/html}
}

@inproceedings{nairRectifiedLinearUnits,
	title = {Rectified linear units improverestricted {Boltzmann} machines},
	url = {https://www.google.com/search?client=firefox-b-d&q=Rectified+linear+units+improverestricted+Boltzmann+machines%5C},
	urldate = {2020-11-28},
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	file = {Rectified linear units improverestricted Boltzmann machines\\ - Google 搜尋:C\:\\Users\\ChingChih\\Zotero\\storage\\HT4YZJLW\\search.html:text/html}
}

@article{salimansWeightNormalizationSimple2016,
	title = {Weight {Normalization}: {A} {Simple} {Reparameterization} to {Accelerate} {Training} of {Deep} {Neural} {Networks}},
	shorttitle = {Weight {Normalization}},
	abstract = {We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.},
	urldate = {2020-11-28},
	journal = {arXiv:1602.07868 [cs]},
	author = {Salimans, Tim and Kingma, Diederik P.},
	month = jun,
	year = {2016},
	note = {arXiv: 1602.07868},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence},
	file = {arXiv Fulltext PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\4UHF6WH6\\Salimans 與 Kingma - 2016 - Weight Normalization A Simple Reparameterization .pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\M5ZV65LL\\1602.html:text/html}
}

@article{terasvirtaPowerPropertiesLinearity2007,
	title = {Power {Properties} of {Linearity} {Tests} for {Time} {Series}},
	volume = {1},
	abstract = {This paper examines the power properties of several linearity tests applied in time-series analysis. The tests are the ones Lee et al.(1993) used in their Monte Carlo study. The main tool used for power comparisons in this paper is the Pitman asymptotic relative efficiency. The results generally strengthen the outcome of the simulations and complement some results in Lee et al. (1993). They also suggest guidelines for designing Monte Carlo experiments for linearity tests.},
	journal = {Studies in Nonlinear Dynamics \& Econometrics},
	author = {Terasvirta, Timo},
	month = feb,
	year = {2007},
	pages = {3--10}
}

@misc{ChapterForecastingEconomic,
	title = {Chapter 8 {Forecasting} economic variables with nonlinear models - {ScienceDirect}},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S1574070605010086},
	urldate = {2020-12-08},
	file = {Chapter 8 Forecasting economic variables with nonlinear models - ScienceDirect:C\:\\Users\\ChingChih\\Zotero\\storage\\CMCFLNBZ\\S1574070605010086.html:text/html}
}

@article{degooijer25YearsTime2006,
	series = {Twenty five years of forecasting},
	title = {25 years of time series forecasting},
	volume = {22},
	issn = {0169-2070},
	url = {http://www.sciencedirect.com/science/article/pii/S0169207006000021},
	doi = {10.1016/j.ijforecast.2006.01.001},
	abstract = {We review the past 25 years of research into time series forecasting. In this silver jubilee issue, we naturally highlight results published in journals managed by the International Institute of Forecasters (Journal of Forecasting 1982–1985 and International Journal of Forecasting 1985–2005). During this period, over one third of all papers published in these journals concerned time series forecasting. We also review highly influential works on time series forecasting that have been published elsewhere during this period. Enormous progress has been made in many areas, but we find that there are a large number of topics in need of further development. We conclude with comments on possible future research directions in this field.},
	language = {en},
	number = {3},
	urldate = {2020-12-08},
	journal = {International Journal of Forecasting},
	author = {De Gooijer, Jan G. and Hyndman, Rob J.},
	month = jan,
	year = {2006},
	keywords = {Accuracy measures, ARCH, ARIMA, Combining, Count data, Densities, Exponential smoothing, Kalman filter, Long memory, Multivariate, Neural nets, Nonlinearity, Prediction intervals, Regime-switching, Robustness, Seasonality, State space, Structural models, Transfer function, Univariate, VAR},
	pages = {443--473},
	file = {ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\TS4MUJ5S\\S0169207006000021.html:text/html;送出的版本:C\:\\Users\\ChingChih\\Zotero\\storage\\ZJ5ZIG8C\\De Gooijer 與 Hyndman - 2006 - 25 years of time series forecasting.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\VWC9Y4TG\\S0169207006000021.html:text/html}
}

@article{koopEstimationForecastingModels2007,
	title = {Estimation and {Forecasting} in {Models} with {Multiple} {Breaks}},
	volume = {74},
	issn = {0034-6527},
	url = {https://doi.org/10.1111/j.1467-937X.2007.00436.x},
	doi = {10.1111/j.1467-937X.2007.00436.x},
	abstract = {This paper develops a new approach to change-point modelling that allows the number of change-points in the observed sample to be unknown. The model we develop assumes that regime durations have a Poisson distribution. It approximately nests the two most common approaches: the time-varying parameter (TVP) model with a change-point every period and the change-point model with a small number of regimes. We focus considerable attention on the construction of reasonable hierarchical priors both for regime durations and for the parameters that characterize each regime. A Markov chain Monte Carlo posterior sampler is constructed to estimate a version of our model, which allows for change in conditional means and variances. We show how real-time forecasting can be done in an efficient manner using sequential importance sampling. Our techniques are found to work well in an empirical exercise involving U.S. GDP growth and inflation. Empirical results suggest that the number of change-points is larger than previously estimated in these series and the implied model is similar to a TVP (with stochastic volatility) model.},
	number = {3},
	urldate = {2020-12-16},
	journal = {The Review of Economic Studies},
	author = {Koop, Gary and Potter, Simon M.},
	month = jul,
	year = {2007},
	pages = {763--789},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\E3RUMIBG\\Koop 與 Potter - 2007 - Estimation and Forecasting in Models with Multiple.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\S6UW6NPW\\1563899.html:text/html}
}

@incollection{clementsChapter12Forecasting2006,
	title = {Chapter 12 {Forecasting} with {Breaks}},
	volume = {1},
	url = {http://www.sciencedirect.com/science/article/pii/S1574070605010128},
	abstract = {A structural break is viewed as a permanent change in the parameter vector of a model. Using taxonomies of all sources of forecast errors for both conditional mean and conditional variance processes, we consider the impacts of breaks and their relevance in forecasting models: (a) where the breaks occur after forecasts are announced; and (b) where they occur in-sample and hence pre-forecasting. The impact on forecasts depends on which features of the models are non-constant. Different models and methods are shown to fare differently in the face of breaks. While structural breaks induce an instability in some parameters of a particular model, the consequences for forecasting are specific to the type of break and form of model. We present a detailed analysis for cointegrated VARs, given the popularity of such models in econometrics. We also consider the detection of breaks, and how to handle breaks in a forecasting context, including ad hoc forecasting devices and the choice of the estimation period. Finally, we contrast the impact of structural break non-constancies with non-constancies due to non-linearity. The main focus is on macro-economic, rather than finance, data, and on forecast biases, rather than higher moments. Nevertheless, we show the relevance of some of the key results for variance processes. An empirical exercise ‘forecasts’ UK unemployment after three major historical crises.},
	language = {en},
	urldate = {2020-12-16},
	booktitle = {Handbook of {Economic} {Forecasting}},
	publisher = {Elsevier},
	author = {Clements, Michael P. and Hendry, David F.},
	editor = {Elliott, G. and Granger, C. W. J. and Timmermann, A.},
	month = jan,
	year = {2006},
	doi = {10.1016/S1574-0706(05)01012-8},
	keywords = {break detection, cointegration, economic forecasting, non-linear models, structural breaks},
	pages = {605--657},
	file = {ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\PB6DEQD6\\S1574070605010128.html:text/html}
}

@techreport{clementsForecastingBreaks2006,
	type = {Handbook of {Economic} {Forecasting}},
	title = {Forecasting with {Breaks}},
	url = {https://econpapers.repec.org/bookchap/eeeecofch/1-12.htm},
	abstract = {A structural break is viewed as a permanent change in the parameter vector of a model. Using taxonomies of all sources of forecast errors for both conditional mean and conditional variance processes, we consider the impacts of breaks and their relevance in forecasting models: (a) where the breaks occur after forecasts are announced; and (b) where they occur in-sample and hence pre-forecasting. The impact on forecasts depends on which features of the models are non-constant. Different models and methods are shown to fare differently in the face of breaks. While structural breaks induce an instability in some parameters of a particular model, the consequences for forecasting are specific to the type of break and form of model. We present a detailed analysis for cointegrated VARs, given the popularity of such models in econometrics. We also consider the detection of breaks, and how to handle breaks in a forecasting context, including ad hoc forecasting devices and the choice of the estimation period. Finally, we contrast the impact of structural break non-constancies with non-constancies due to non-linearity. The main focus is on macro-economic, rather than finance, data, and on forecast biases, rather than higher moments. Nevertheless, we show the relevance of some of the key results for variance processes. An empirical exercise `forecasts' UK unemployment after three major historical crises.},
	urldate = {2020-12-16},
	institution = {Elsevier},
	author = {Clements, Michael and Hendry, David},
	year = {2006},
	pages = {605--657},
	file = {RePEc Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\AVNEFECX\\1-12.html:text/html}
}

@article{junttilaStructuralBreaksARIMA2001,
	title = {Structural breaks, {ARIMA} model and {Finnish} inflation forecasts},
	volume = {17},
	issn = {0169-2070},
	url = {http://www.sciencedirect.com/science/article/pii/S0169207000000807},
	doi = {10.1016/S0169-2070(00)00080-7},
	abstract = {Via the use of the rolling regression technique and a specific procedure for analysing strong structural breaks in a univariate time series model, we forecast the rate of future inflation in Finland for the time period of unregulated financial markets since the beginning of 1987. The identified structural changes in the data generating process (DGP) of inflation are labelled with both economic events and changes in the main leading inflation indicators. The final intervention model yields, in some cases, better forecasts than the pure rolling regression technique without identification of the strong breaks. When comparing the obtained forecasts with certain noncontinuous time series based on inflation expectation surveys with respect to actual future inflation, we find that the comparable point forecasts from our rolling regressions perform better than the corresponding point expectation proxies from questionnaires. When compared with the performance of the forecasts by the Research Institute of the Finnish Economy, the recursive procedure also produces more accurate forecasts.},
	language = {en},
	number = {2},
	urldate = {2020-12-16},
	journal = {International Journal of Forecasting},
	author = {Junttila, Juha},
	month = apr,
	year = {2001},
	keywords = {AR(I)MA models, Forecasting, Structural breaks, Time variation},
	pages = {203--230},
	file = {ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\HN43QJT3\\S0169207000000807.html:text/html}
}

@misc{ReviewUnemploymentJSTOR,
	title = {A {Review} of {Unemployment} on {JSTOR}},
	url = {https://www.jstor.org/stable/2728066?seq=1#metadata_info_tab_contents},
	urldate = {2020-12-16},
	file = {A Review of Unemployment on JSTOR:C\:\\Users\\ChingChih\\Zotero\\storage\\9NL9DNBM\\2728066.html:text/html}
}

@article{elliottEconomicForecasting2008,
	title = {Economic {Forecasting}},
	volume = {46},
	issn = {0022-0515},
	abstract = {Forecasts guide decisions in all areas of economics and finance and their value can
only be understood in relation to, and in the context of, such decisions. We discuss
the central role of the loss function in helping determine the forecaster's objectives.
Decision theory provides a framework for both the construction and evaluation of
forecasts. This framework allows an understanding of the challenges that arise from
the explosion in the sheer volume of predictor variables under consideration and the
forecaster's ability to entertain an endless array of forecasting models and time-varying
specifications, none of which may coincide with the "true" model. We show this
along with reviewing methods for comparing the forecasting performance of pairs
of models or evaluating the ability of the best of many models to beat a benchmark
specification.},
	language = {en},
	number = {1},
	urldate = {2020-12-16},
	journal = {Journal of Economic Literature},
	author = {Elliott, Graham and Timmermann, Allan},
	month = mar,
	year = {2008},
	keywords = {Forecasting and Other Model Applications},
	pages = {3--56},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\VEV2VJB9\\articles.html:text/html}
}

@misc{IDENTIFYINGNEWSSHOCKS,
	title = {{IDENTIFYING} {NEWS} {SHOCKS} {WITH} {FORECAST} {DATA} {\textbar} {Macroeconomic} {Dynamics} {\textbar} {Cambridge} {Core}},
	url = {https://www.cambridge.org/core/journals/macroeconomic-dynamics/article/identifying-news-shocks-with-forecast-data/E50C8B80B0A4E7EB2421FBC73C0AA9E2},
	urldate = {2020-12-16},
	file = {IDENTIFYING NEWS SHOCKS WITH FORECAST DATA | Macroeconomic Dynamics | Cambridge Core:C\:\\Users\\ChingChih\\Zotero\\storage\\SK9EXGCH\\E50C8B80B0A4E7EB2421FBC73C0AA9E2.html:text/html}
}

@article{hiroseIDENTIFYINGNEWSSHOCKSundefined/ed,
	title = {{IDENTIFYING} {NEWS} {SHOCKS} {WITH} {FORECAST} {DATA}},
	issn = {1365-1005, 1469-8056},
	url = {https://www.cambridge.org/core/journals/macroeconomic-dynamics/article/identifying-news-shocks-with-forecast-data/E50C8B80B0A4E7EB2421FBC73C0AA9E2},
	doi = {10.1017/S1365100519000737},
	abstract = {The empirical importance of news shocks—anticipated future shocks—in business cycle fluctuations has been explored by using only actual data when estimating models augmented with news shocks. This paper additionally exploits forecast data to identify news shocks in a canonical dynamic stochastic general equilibrium model. The estimated model shows new empirical evidence that technology news shocks are a major source of fluctuations in US output growth. Exploiting the forecast data not only generates more precise estimates of news shocks and other parameters in the model, but also increases the contribution of technology news shocks to the fluctuations.},
	language = {en},
	urldate = {2020-12-16},
	journal = {Macroeconomic Dynamics},
	author = {Hirose, Yasuo and Kurozumi, Takushi},
	note = {Publisher: Cambridge University Press},
	keywords = {Bayesian Estimation, Business Cycle Fluctuation, Forecast Data, Technology News Shock, Technology Shock},
	pages = {1--30},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\GM9FQ9MU\\Hirose 與 Kurozumi - IDENTIFYING NEWS SHOCKS WITH FORECAST DATA.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\XGMNR6GB\\E50C8B80B0A4E7EB2421FBC73C0AA9E2.html:text/html}
}

@article{phelpsReviewUnemployment1992,
	title = {A {Review} of {Unemployment}},
	volume = {30},
	issn = {0022-0515},
	url = {https://www.jstor.org/stable/2728066},
	number = {3},
	urldate = {2020-12-16},
	journal = {Journal of Economic Literature},
	author = {Phelps, Edmund S.},
	editor = {Layard, Richard and Nickell, Stephen and Jackman, Richard},
	year = {1992},
	note = {Publisher: American Economic Association},
	pages = {1476--1490}
}

@book{layardUnemploymentMacroeconomicPerformance1991,
	title = {Unemployment: {Macroeconomic} {Performance} and the {Labour} {Market}},
	isbn = {978-0-19-170003-3},
	shorttitle = {Unemployment},
	abstract = {"Unemployment" published on  by Oxford University Press.},
	language = {en\_US},
	urldate = {2020-12-16},
	publisher = {Oxford University Press},
	author = {Layard, Richard and Nickell, Stephen and Jackman, Richard},
	year = {1991},
	note = {Publication Title: Unemployment},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\YRYLUYCG\\acprof-9780199279166.html:text/html}
}

@article{dritsakiForecastSarimaModels2016,
	title = {Forecast of {Sarima} {Models}: Αn {Application} to {Unemployment} {Rates} of {Greece}},
	volume = {4},
	shorttitle = {Forecast of {Sarima} {Models}},
	abstract = {The low unemployment rate is one of the main targets of macroeconomic policy for each government. Forecasting unemployment rate is of great importance for each country so as the government can draw up strategies for fiscal policy. The aim of the paper is to find the most suitable model which is adjusted on unemployment rates of Greece using Box-Jenkins methodology and to examine the precision of forecasting on this model. Models’ estimation was made using the non-linear Maximum likelihood optimization methodology (maximum likelihood–ML), whereas covariance matrix is estimated with OPG method using the numerical optimization of Broyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. Forecasting unemployment rate was made both with dynamic and static process using all criteria of forecasting measures.},
	number = {5},
	urldate = {2020-12-16},
	journal = {American Journal of Applied Mathematics and Statistics},
	author = {Dritsaki, Chaido},
	month = sep,
	year = {2016},
	pages = {136--148},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\ECPHMWXX\\Dritsaki - 2016 - Forecast of Sarima Models Αn Application to Unemp.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\8K9TC97H\\1.html:text/html}
}

@article{bootDoesModelingStructural2020,
	title = {Does modeling a structural break improve forecast accuracy?},
	volume = {215},
	issn = {0304-4076},
	abstract = {Mean square forecast error loss implies a bias–variance trade-off that suggests that structural breaks of small magnitude should be ignored. In this paper, we provide a test to determine whether modeling a structural break improves forecast accuracy. The test is near optimal even when the date of a local-to-zero break is not consistently estimable. The results extend to forecast combinations that weight the post-break sample and the full sample forecasts by our test statistic. In a large number of macroeconomic time series, we find that structural breaks that are relevant for forecasting occur much less frequently than existing tests indicate.},
	language = {en},
	number = {1},
	urldate = {2020-12-23},
	journal = {Journal of Econometrics},
	author = {Boot, Tom and Pick, Andreas},
	month = mar,
	year = {2020},
	keywords = {Forecasting, Squared error loss, Structural break test},
	pages = {35--59},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\3N5C2Y84\\Boot 與 Pick - 2020 - Does modeling a structural break improve forecast .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\JZM66VPK\\S0304407619301824.html:text/html}
}

@article{coulombeHowMachineLearning2020,
	title = {How is {Machine} {Learning} {Useful} for {Macroeconomic} {Forecasting}?},
	abstract = {We move beyond "Is Machine Learning Useful for Macroeconomic Forecasting?" by
adding the "how". The current forecasting literature has focused on matching
specific variables and horizons with a particularly successful algorithm. In
contrast, we study the usefulness of the underlying features driving ML gains
over standard macroeconometric methods. We distinguish four so-called features
(nonlinearities, regularization, cross-validation and alternative loss
function) and study their behavior in both the data-rich and data-poor
environments. To do so, we design experiments that allow to identify the
"treatment" effects of interest. We conclude that (i) nonlinearity is the true
game changer for macroeconomic prediction, (ii) the standard factor model
remains the best regularization, (iii) K-fold cross-validation is the best
practice and (iv) the \$L\_2\$ is preferred to the \${\textbackslash}bar ε\$-insensitive
in-sample loss. The forecasting gains of nonlinear techniques are associated
with high macroeconomic uncertainty, financial stress and housing bubble
bursts. This suggests that Machine Learning is useful for macroeconomic
forecasting by mostly capturing important nonlinearities that arise in the
context of uncertainty and financial frictions.},
	language = {en},
	urldate = {2020-12-23},
	author = {Coulombe, Philippe Goulet and Leroux, Maxime and Stevanovic, Dalibor and Surprenant, Stéphane},
	month = aug,
	year = {2020},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\XIXIR48R\\Coulombe 等。 - 2020 - How is Machine Learning Useful for Macroeconomic F.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\Z6RNY5E6\\2008.html:text/html}
}

@techreport{uscensusbureauX13ARIMASEATSSeasonalAdjustment2017,
	title = {X-{13ARIMA}-{SEATS} {Seasonal} {Adjustment} {Program}},
	url = {https://www.census.gov/srd/www/x13as/},
	abstract = {US Census Bureau - X-13ARIMA-SEATS seasonal adjustment software and supporting programs and utilities can be downloaded from here.},
	language = {EN-US},
	urldate = {2020-12-23},
	institution = {US Census Bureau},
	author = {US Census Bureau, Brian C. Monsell},
	year = {2017},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\TJTCAI82\\x13as.html:text/html}
}

@misc{zotero-124,
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwicl5SL1OXtAhURqpQKHWRcBhgQFjAAegQIARAC&url=https%3A%2F%2Fwww.annualreviews.org%2Fdoi%2Fabs%2F10.1146%2Fannurev-economics-080315-015346&usg=AOvVaw15keBFFZiteZX91QLuT1cG},
	urldate = {2020-12-24}
}

@misc{UncertaintyLaborMarket,
	title = {Uncertainty and {Labor} {Market} {Fluctuations}},
	url = {https://www.dallasfed.org:443/research/papers/2019/wp1904},
	abstract = {We investigate how a macroeconomic uncertainty shock affects the labor market.},
	language = {en},
	urldate = {2020-12-25},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\34GIFZL6\\wp1904.html:text/html}
}

@article{carrieroMeasuringUncertaintyIts2018,
	title = {Measuring {Uncertainty} and {Its} {Impact} on the {Economy}},
	volume = {100},
	url = {https://ideas.repec.org/a/tpr/restat/v100y2018i5p799-815.html},
	abstract = {We propose a new model for measuring uncertainty and its effects on the economy, based on a large vector autoregression with stochastic volatility driven by common factors representing macroeconomic and financial uncertainty. The uncertainty measures reflect changes in both the conditional mean and volatility of the variables, and their impact on the economy can be assessed within the same framework. Estimates with U.S. data show substantial commonality in uncertainty, with sizable effects of uncertainty on key macroeconomic and financial variables. However, historical decompositions show a limited role of uncertainty shocks in macroeconomic fluctuations.},
	language = {en},
	number = {5},
	urldate = {2020-12-25},
	journal = {The Review of Economics and Statistics},
	author = {Carriero, Andrea and Clark, Todd E. and Marcellino, Massimiliano},
	year = {2018},
	note = {Publisher: MIT Press},
	pages = {799--815},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\SJGHWIDZ\\v100y2018i5p799-815.html:text/html}
}

@misc{ArtificialNeuralNetworks,
	title = {Artificial {Neural} {Networks} {\textbar} {SpringerLink}},
	url = {https://link.springer.com/chapter/10.1007/978-3-319-20010-1_5},
	urldate = {2020-12-25}
}

@article{kuanArtificialNeuralNetworks1994,
	title = {Artificial neural networks: an econometric perspective},
	volume = {13},
	issn = {0747-4938},
	shorttitle = {Artificial neural networks},
	doi = {10.1080/07474939408800273},
	number = {1},
	urldate = {2020-12-25},
	journal = {Econometric Reviews},
	author = {Kuan, Chung-Ming and White, Halbert},
	month = jan,
	year = {1994},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/07474939408800273},
	pages = {1--91},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\GVLDHHLS\\07474939408800273.html:text/html}
}

@article{swansonModelSelectionApproach1997,
	title = {A {Model} {Selection} {Approach} {To} {Real}-{Time} {Macroeconomic} {Forecasting} {Using} {Linear} {Models} {And} {Artificial} {Neural} {Networks}},
	volume = {79},
	abstract = {We take a model selection approach to the question of whether a class of adaptive prediction models (artificial neural networks) is useful for predicting future values of nine macroeconomic variables. We use a variety of out-of-sample forecast-based model selection criteria, including forecast error measures and forecast direction accuracy. Ex ante or real-time forecasting results based on rolling window prediction methods indicate that multivariate adaptive linear vector autoregression models often outperform a variety of (1) adaptive and nonadaptive univariate models, (2) nonadaptive multivariate models, (3) adaptive nonlinear models, and (4) professionally available survey predictions. Further, model selection based on the in-sample Schwarz information criterion apparently fails to offer a convenient shortcut to true out-of-sample performance measures. © 1997 by the President and Fellows of Harvard College and the Massachusetts Institute of Technology},
	number = {4},
	urldate = {2020-12-25},
	journal = {The Review of Economics and Statistics},
	author = {Swanson, Norman and White, Halbert},
	year = {1997},
	note = {Publisher: MIT Press},
	pages = {540--550},
	file = {RePEc Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\6WKSFPEU\\v_3a79_3ay_3a1997_3ai_3a4_3ap_3a540-550.html:text/html}
}

@book{stockCointegrationCausalityForecasting1999,
	address = {Oxford},
	title = {Cointegration, {Causality} and {Forecasting}: {A} {Festschrift} for {Clive} {W}.{J}. {Granger}},
	shorttitle = {Cointegration, {Causality} and {Forecasting}},
	publisher = {Oxford University Press},
	author = {Stock, James and Watson, M.},
	year = {1999},
	note = {Pages: 1-44},
	file = {A Comparison of Linear and Nonlinear Univariate Models for Forecasting Macroeconomic Time Series | James Stock:C\:\\Users\\ChingChih\\Zotero\\storage\\FXGAPAZ6\\comparison-linear-and-nonlinear-univariate-models-forecasting-macroeconomic-time.html:text/html}
}

@article{stockEvidenceStructuralInstability1996,
	title = {Evidence on {Structural} {Instability} in {Macroeconomic} {Time} {Series} {Relations}},
	volume = {14},
	url = {https://econpapers.repec.org/article/besjnlbes/v_3a14_3ay_3a1996_3ai_3a1_3ap_3a11-30.htm},
	abstract = {An experiment is performed to assess the prevalence of instability in univariate and bivariate macroeconomic time series relations and to ascertain whether various adaptive forecasting techniques successfully handle any such instability. Formal tests for instability and out-of-sample forecasts from sixteen different models are computed using a sample of seventy-six representative U.S. monthly postwar macroeconomic time series, constituting 5,700 bivariate forecasting relations. The tests for instability and the forecast comparisons suggest that there is substantial instability in a significant fraction of the univariate and bivariate autoregressive models.},
	number = {1},
	urldate = {2020-12-27},
	journal = {Journal of Business \& Economic Statistics},
	author = {Stock, James and Watson, Mark},
	year = {1996},
	note = {Publisher: American Statistical Association},
	pages = {11--30},
	file = {RePEc Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\AQJVRP8J\\v_3a14_3ay_3a1996_3ai_3a1_3ap_3a11-30.html:text/html}
}

@misc{160903499WaveNet,
	title = {[1609.03499] {WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
	url = {https://arxiv.org/abs/1609.03499},
	urldate = {2020-12-27},
	file = {[1609.03499] WaveNet\: A Generative Model for Raw Audio:C\:\\Users\\ChingChih\\Zotero\\storage\\LTX5BQB3\\1609.html:text/html}
}

@article{oordWaveNetGenerativeModel2016,
	title = {{WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
	shorttitle = {{WaveNet}},
	abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
	urldate = {2020-12-27},
	journal = {arXiv:1609.03499 [cs]},
	author = {Oord, Aaron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	month = sep,
	year = {2016},
	keywords = {Computer Science - Machine Learning, Computer Science - Sound},
	file = {arXiv Fulltext PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\ZSH6TGJE\\Oord 等。 - 2016 - WaveNet A Generative Model for Raw Audio.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\P76UIRYJ\\1609.html:text/html}
}

@article{kalchbrennerNeuralMachineTranslation,
	title = {Neural {Machine} {Translation} in {Linear} {Time}},
	urldate = {2020-12-27},
	journal = {https://arxiv.org/abs/1610.10099},
	author = {Kalchbrenner, Nal and Espeholt, Lasse and Simonyan, Karen and Oord, Aaron van den and Graves, Alex and Kavukcuoglu, Koray},
	file = {[1610.10099] Neural Machine Translation in Linear Time:C\:\\Users\\ChingChih\\Zotero\\storage\\LRSMECRV\\1610.html:text/html}
}

@misc{AnguageModelingGated,
	title = {anguage modeling with gated convolutional networks - {Google} 搜尋},
	url = {https://www.google.com/search?client=firefox-b-d&q=anguage+modeling+with+gated+convolutional+networks},
	urldate = {2020-12-27},
	file = {anguage modeling with gated convolutional networks - Google 搜尋:C\:\\Users\\ChingChih\\Zotero\\storage\\23SP4FFB\\search.html:text/html}
}

@article{dauphinLanguageModelingGated2017,
	title = {Language {Modeling} with {Gated} {Convolutional} {Networks}},
	abstract = {The pre-dominant approach to language modeling to date is based on recurrent neural networks. Their success on this task is often linked to their ability to capture unbounded context. In this paper we develop a finite context approach through stacked convolutions, which can be more efficient since they allow parallelization over sequential tokens. We propose a novel simplified gating mechanism that outperforms Oord et al (2016) and investigate the impact of key architectural decisions. The proposed approach achieves state-of-the-art on the WikiText-103 benchmark, even though it features long-term dependencies, as well as competitive results on the Google Billion Words benchmark. Our model reduces the latency to score a sentence by an order of magnitude compared to a recurrent baseline. To our knowledge, this is the first time a non-recurrent approach is competitive with strong recurrent models on these large scale language tasks.},
	urldate = {2020-12-27},
	journal = {arXiv:1612.08083 [cs]},
	author = {Dauphin, Yann N. and Fan, Angela and Auli, Michael and Grangier, David},
	month = sep,
	year = {2017},
	keywords = {Computer Science - Computation and Language},
	file = {arXiv Fulltext PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\ZMRRRPUC\\Dauphin 等。 - 2017 - Language Modeling with Gated Convolutional Network.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\EJFFLXDR\\1612.html:text/html}
}

@article{zivotFurtherEvidenceGreat1992,
	title = {Further {Evidence} on the {Great} {Crash}, the {Oil}-{Price} {Shock}, and the {Unit}-{Root} {Hypothesis}},
	volume = {10},
	issn = {0735-0015},
	abstract = {Recently, Perron has carried out tests of the unit-root hypothesis against the alternative hypothesis of trend stationarity with a break in the trend occurring at the Great Crash of 1929 or at the 1973 oil-price shock. His analysis covers the Nelson-Plosser macroeconomic data series as well as a postwar quarterly real gross national product (GNP) series. His tests reject the unit-root null hypothesis for most of the series. This article takes issue with the assumption used by Perron that the Great Crash and the oil-price shock can be treated as exogenous events. A variation of Perron's test is considered in which the breakpoint is estimated rather than fixed. We argue that this test is more appropriate than Perron's because it circumvents the problem of data-mining. The asymptotic distribution of the estimated breakpoint test statistic is determined. The data series considered by Perron are reanalyzed using this test statistic. The empirical results make use of the asymptotics developed for the test statistic as well as extensive finite-sample corrections obtained by simulation. The effect on the empirical results of fat-tailed and temporally dependent innovations is investigated. In brief, by treating the breakpoint as endogenous, we find that there is less evidence against the unit-root hypothesis than Perron finds for many of the data series but stronger evidence against it for several of the series, including the Nelson-Plosser industrial-production, nominal-GNP, and real-GNP series.},
	number = {3},
	urldate = {2020-12-27},
	journal = {Journal of Business \& Economic Statistics},
	author = {Zivot, Eric and Andrews, Donald W. K.},
	year = {1992},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {251--270},
	file = {JSTOR Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\LXLYW92D\\Zivot 與 Andrews - 1992 - Further Evidence on the Great Crash, the Oil-Price.pdf:application/pdf}
}

@article{baiComputationAnalysisMultiple2003,
	title = {Computation and analysis of multiple structural change models},
	volume = {18},
	copyright = {Copyright © 2003 John Wiley \& Sons, Ltd.},
	issn = {1099-1255},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jae.659},
	abstract = {In a recent paper, Bai and Perron (1998) considered theoretical issues related to the limiting distribution of estimators and test statistics in the linear model with multiple structural changes. In this companion paper, we consider practical issues for the empirical applications of the procedures. We first address the problem of estimation of the break dates and present an efficient algorithm to obtain global minimizers of the sum of squared residuals. This algorithm is based on the principle of dynamic programming and requires at most least-squares operations of order O(T2) for any number of breaks. Our method can be applied to both pure and partial structural change models. Second, we consider the problem of forming confidence intervals for the break dates under various hypotheses about the structure of the data and the errors across segments. Third, we address the issue of testing for structural changes under very general conditions on the data and the errors. Fourth, we address the issue of estimating the number of breaks. Finally, a few empirical applications are presented to illustrate the usefulness of the procedures. All methods discussed are implemented in a GAUSS program. Copyright © 2002 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2020-12-28},
	journal = {Journal of Applied Econometrics},
	author = {Bai, Jushan and Perron, Pierre},
	year = {2003},
	pages = {1--22},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\CHKZ7B9T\\Bai 與 Perron - 2003 - Computation and analysis of multiple structural ch.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\U3EUCF52\\jae.html:text/html}
}

@book{stiglitzPeoplePowerProfits2019,
	address = {New York},
	title = {People, {Power}, and {Profits}: {Progressive} {Capitalism} for an {Age} of {Discontent}},
	isbn = {978-1-324-00421-9},
	shorttitle = {People, {Power}, and {Profits}},
	abstract = {A Nobel prize winner challenges us to throw off the free market fundamentalists and reclaim our economy.We all have the sense that the American economy―and its government―tilts toward big business, but as Joseph E. Stiglitz explains in his new book, People, Power, and Profits, the situation is dire. A few corporations have come to dominate entire sectors of the economy, contributing to skyrocketing inequality and slow growth. This is how the financial industry has managed to write its own regulations, tech companies have accumulated reams of personal data with little oversight, and our government has negotiated trade deals that fail to represent the best interests of workers. Too many have made their wealth through exploitation of others rather than through wealth creation. If something isn’t done, new technologies may make matters worse, increasing inequality and unemployment.Stiglitz identifies the true sources of wealth and of increases in standards of living, based on learning, advances in science and technology, and the rule of law. He shows that the assault on the judiciary, universities, and the media undermines the very institutions that have long been the foundation of America’s economic might and its democracy.Helpless though we may feel today, we are far from powerless. In fact, the economic solutions are often quite clear. We need to exploit the benefits of markets while taming their excesses, making sure that markets work for us―the U.S. citizens―and not the other way around. If enough citizens rally behind the agenda for change outlined in this book, it may not be too late to create a progressive capitalism that will recreate a shared prosperity. Stiglitz shows how a middle-class life can once again be attainable by all.An authoritative account of the predictable dangers of free market fundamentalism and the foundations of progressive capitalism, People, Power, and Profits shows us an America in crisis, but also lights a path through this challenging time. 2 charts},
	author = {Stiglitz, Joseph E.},
	month = apr,
	year = {2019}
}

@misc{POLITICALECONOMYINTERNATIONAL,
	title = {{THE} {POLITICAL} {ECONOMY} {OF} {INTERNATIONAL} {TRADE} {\textbar} {Annual} {Review} of {Political} {Science}},
	url = {https://www.annualreviews.org/doi/abs/10.1146/annurev.polisci.2.1.91},
	urldate = {2021-01-05},
	file = {THE POLITICAL ECONOMY OF INTERNATIONAL TRADE | Annual Review of Political Science:C\:\\Users\\ChingChih\\Zotero\\storage\\ACT4USS9\\annurev.polisci.2.1.html:text/html}
}

@article{milnerPOLITICALECONOMYINTERNATIONAL1999,
	title = {{THE} {POLITICAL} {ECONOMY} {OF} {INTERNATIONAL} {TRADE}},
	url = {https://arch.neicon.ru/xmlui/handle/123456789/1940968},
	urldate = {2021-01-05},
	journal = {Annual Review of Political Science},
	author = {Milner, Helen V.},
	year = {1999},
	file = {THE POLITICAL ECONOMY OF INTERNATIONAL TRADE:C\:\\Users\\ChingChih\\Zotero\\storage\\LZWMKGTU\\1940968.html:text/html}
}

@misc{TechnologyTradeFactor,
	title = {Technology, {Trade} and {Factor} {Prices} - {Google} 搜尋},
	url = {https://www.google.com/search?client=firefox-b-d&q=Technology%2C+Trade+and+Factor+Prices},
	urldate = {2021-01-05},
	file = {Technology, Trade and Factor Prices - Google 搜尋:C\:\\Users\\ChingChih\\Zotero\\storage\\RAIGQNL3\\search.html:text/html}
}

@article{krugmanTechnologyTradeFactor2000,
	title = {Technology, trade and factor prices},
	volume = {50},
	issn = {0022-1996},
	url = {http://www.sciencedirect.com/science/article/pii/S0022199699000161},
	doi = {10.1016/S0022-1996(99)00016-1},
	abstract = {The view that recent changes in the distribution of income primarily reflect technology rather than trade may be the majority opinion, but has been harshly criticized by some trade economists. This paper will argue that the critique in fact misses the point, essentially because the critics undertake the wrong thought experiments. Trade volumes are not irrelevant: if one poses the question correctly, one immediately realizes that small trade volumes are inconsistent with a story that attributes large distributional effects to trade. The factor bias of technological change is not immaterial, except in the case where such change takes place in a small open economy (as opposed to one that can affect world prices), and where technical change occurs only in that economy (rather than occurring simultaneously in other economies as well); since the real situation does not meet either criterion, factor bias definitely does matter. Most surprisingly, the much maligned use of a factor content approach to infer the effects of trade on factor prices turns out to be an entirely justified procedure when carefully applied.},
	language = {en},
	number = {1},
	urldate = {2021-01-05},
	journal = {Journal of International Economics},
	author = {Krugman, Paul R},
	month = feb,
	year = {2000},
	keywords = {Factor prices, Technology, Trade},
	pages = {51--71},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\LMC7CC4J\\Krugman - 2000 - Technology, trade and factor prices.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\MMLGIBAH\\S0022199699000161.html:text/html}
}

@article{ebensteinEstimatingImpactTrade2014,
	title = {Estimating the {Impact} of {Trade} and {Offshoring} on {American} {Workers} {Using} the {Current} {Population} {Surveys}},
	url = {https://repository.upenn.edu/mgmt_papers/104},
	doi = {10.1162/REST_a_00400},
	journal = {The Review of Economics and Statistics},
	author = {Ebenstein, Avraham and Harrison, Ann and McMillan, Margaret and Phillips, Shannon},
	month = oct,
	year = {2014},
	pages = {581--595},
	file = {送出的版本:C\:\\Users\\ChingChih\\Zotero\\storage\\KMP4ZMRY\\Ebenstein 等。 - 2014 - Estimating the Impact of Trade and Offshoring on A.pdf:application/pdf;"Estimating the Impact of Trade and Offshoring on American Workers Usin" by Avraham Ebenstein, Ann E. Harrison et al.:C\:\\Users\\ChingChih\\Zotero\\storage\\LD4PETKW\\104.html:text/html}
}

@article{autorChinaSyndromeLocal2013,
	title = {The {China} {Syndrome}: {Local} {Labor} {Market} {Effects} of {Import} {Competition} in the {United} {States}},
	volume = {103},
	issn = {0002-8282},
	shorttitle = {The {China} {Syndrome}},
	url = {https://www.aeaweb.org/articles?id=10.1257/aer.103.6.2121},
	doi = {10.1257/aer.103.6.2121},
	abstract = {We analyze the effect of rising Chinese import competition between
1990 and 2007 on US local labor markets, exploiting cross-
market
variation in import exposure stemming from initial differences in
industry specialization and instrumenting for US imports using
changes in Chinese imports by other high-income countries. Rising
imports cause higher unemployment, lower labor force participation,
and reduced wages in local labor markets that house import-competing
manufacturing industries. In our main specification,
import competition explains one-quarter of the contemporaneous
aggregate decline in US manufacturing employment. Transfer
benefits payments for unemployment, disability, retirement, and
healthcare also rise sharply in more trade-exposed labor markets.},
	language = {en},
	number = {6},
	urldate = {2021-01-05},
	journal = {American Economic Review},
	author = {Autor, David H. and Dorn, David and Hanson, Gordon H.},
	month = oct,
	year = {2013},
	keywords = {Aggregate Human Capital, Empirical Studies of Trade, Trade and Labor Market Interactions, Industry Studies: Manufacturing: General, Measurement of Economic Growth, Aggregate Productivity, Cross-Country Output Convergence, Size and Spatial Distributions of Regional Economic Activity, Urban, Rural, Regional, Real Estate, and Transportation Economics: Regional Migration, Employment, Intergenerational Income Distribution, Neighborhood Characteristics, Population, Regional Labor Markets, Unemployment, Wages},
	pages = {2121--2168},
	file = {Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\4E7K5FYH\\Autor 等。 - 2013 - The China Syndrome Local Labor Market Effects of .pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\5XMK67ML\\articles.html:text/html;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\D2B5USFB\\articles.html:text/html}
}

@article{zeileisTestingDatingStructural2003,
	title = {Testing and {Dating} of {Structural} {Changes} in {Practice}},
	volume = {44},
	abstract = {An approach to the analysis of data that contains (multiple) structural changes in a linear regression setup is presented. Various strategies which have been suggested in the literature for testing against structural changes as well as a dynamic programming algorithm for the dating of the breakpoints are implemented in the R statistical software package. Using historical data on Nile river discharges, road casualties in Great Britain and oil prices in Germany, it is shown that statistically detected changes in the mean of a time series as well as in the coefficients of a linear regression coincide with identifiable historical, political or economic events which might have caused these breaks.},
	journal = {Computational Statistics \& Data Analysis},
	author = {Zeileis, Achim and Kleiber, Christian and Krämer, Walter and Hornik, Kurt},
	month = feb,
	year = {2003},
	pages = {109--123},
	file = {送出的版本:C\:\\Users\\ChingChih\\Zotero\\storage\\FARSSLRW\\Zeileis 等。 - 2003 - Testing and Dating of Structural Changes in Practi.pdf:application/pdf}
}

@misc{zotero-190,
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwismuexrIbuAhUKkJQKHVXdCckQFjABegQIAxAC&url=https%3A%2F%2Fwww.cambridge.org%2Fcore%2Fbooks%2Feconometric-theory-and-practice%2Fmultiple-structural-change-models-a-simulation-analysis%2FE0DFD2531E66B2B1A4516EB8B99C6E36&usg=AOvVaw0aGJFaNT9Jw1CQAcFzXbVy},
	urldate = {2021-01-06}
}

@incollection{baiMultipleStructuralChanges2006,
	title = {Multiple {Structural} {Changes}: {A} {Simulation} {Analysis}},
	shorttitle = {Multiple {Structural} {Changes}},
	abstract = {INTRODUCTION Both the statistics and econometrics literature contain a vast amount of work on issues related to structural change, most of it specifically designed for the case of a single change. The problem of multiple structural changes, however, has received considerably less attention. Recently, Bai and Perron (1998, 2003a) provided a comprehensive treatment of various issues in the context of multiple structural change models: consistency of estimates of the break dates, tests for structural changes, confidence intervals for the break dates, methods to select the number of breaks, and efficient algorithms to compute the estimates. Their results are solely asymptotic, however, and the adequacy in finite samples remains to be investigated. This chapter is intended to fill this gap partially. We present simulation results pertaining to the behavior of the estimators and tests in finite samples. We consider the problem of forming confidence intervals for the break dates under various hypotheses about the structure of the data and errors across segments. In particular, we may allow the data and errors to have different distributions across segments or impose a common structure. The issue of testing for structural changes is also considered under very general conditions on the data and the errors and the properties of tests – both in the data-generating processes and in the specification of the tests. We also address the issue of estimating the number of breaks.},
	booktitle = {Econometric {Theory} and {Practice}: {Frontiers} of {Analysis} and {Applied} {Research}},
	author = {Bai, Jushan and Perron, Pierre},
	month = jan,
	year = {2006},
	doi = {10.1017/CBO9781139164863.010},
	note = {Journal Abbreviation: Econometric Theory and Practice: Frontiers of Analysis and Applied Research},
	pages = {212--237},
	file = {全文:C\:\\Users\\ChingChih\\Zotero\\storage\\VMPC9W2E\\Bai 與 Perron - 2006 - Multiple Structural Changes A Simulation Analysis.pdf:application/pdf}
}

@article{terasvirtaPowerNeuralNetwork1993,
	title = {Power of the {Neural} {Network} {Linearity} {Test}},
	volume = {14},
	issn = {1467-9892},
	doi = {https://doi.org/10.1111/j.1467-9892.1993.tb00139.x},
	abstract = {Abstract. Recently, a new linearity test for time series was introduced based on concepts from the theory of neural networks. Lee et al. have already studied the power properties of this test and they are further investigated here. They are compared by simulation with those of a Lagrange multiplier (LM) type test that we derive from the same single-hidden-layer neural network model. The auxiliary regression of our LM type test is a simple cubic ‘dual’ of the Volterra expansion of the original series, and the power of the test appears superior overall to that of the other test.},
	language = {en},
	number = {2},
	urldate = {2021-01-06},
	journal = {Journal of Time Series Analysis},
	author = {Teräsvirta, Timo and Lin, Chien-Fu and Granger, Clive W. J.},
	year = {1993},
	keywords = {Lagrange multiplier test, linearity testing, neural network, nonlinear time series, Volterra expansion},
	pages = {209--220}
}

@misc{160903499WaveNeta,
	title = {[1609.03499] {WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
	url = {https://arxiv.org/abs/1609.03499},
	urldate = {2021-01-07},
	file = {[1609.03499] WaveNet\: A Generative Model for Raw Audio:C\:\\Users\\ChingChih\\Zotero\\storage\\7LHAW5Y3\\1609.html:text/html}
}

@article{ghyselsSeasonalAdjustmentLinear1996,
	title = {Is {Seasonal} {Adjustment} a {Linear} or {Nonlinear} {Data}-{Filtering} {Process}?},
	volume = {14},
	issn = {0735-0015},
	url = {https://www.jstor.org/stable/1392449},
	doi = {10.2307/1392449},
	abstract = {We investigate whether seasonal-adjustment procedures are, at least approximately, linear data transformations. This question was initially addressed by Young and is important with respect to many issues including estimation of regression models with seasonally adjusted data. We focus on the X-11 program and rely on simulation evidence, involving linear unobserved component autoregressive integrated moving average models. We define a set of properties for the adequacy of a linear approximation to a seasonal-adjustment filter. These properties are examined through statistical tests. Next, we study the effect of X-11 seasonal adjustment on regression statistics assessing the statistical significance of the relationship between economic variables. Several empirical results involving economic data are also reported.},
	number = {3},
	urldate = {2021-01-08},
	journal = {Journal of Business \& Economic Statistics},
	author = {Ghysels, Eric and Granger, Clive W. J. and Siklos, Pierre L.},
	year = {1996},
	note = {Publisher: [American Statistical Association, Taylor \& Francis, Ltd.]},
	pages = {374--386},
	file = {JSTOR Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\TU4U3TD7\\Ghysels 等。 - 1996 - Is Seasonal Adjustment a Linear or Nonlinear Data-.pdf:application/pdf}
}

@misc{AmazonComTimea,
	title = {Amazon.com：{Time} {Series} {Analysis}: {Forecasting} and {Control} ({Wiley} {Series} in {Probability} and {Statistics}) (9781118675021): {Box}, {George} {E}. {P}., {Jenkins}, {Gwilym} {M}., {Reinsel}, {Gregory} {C}., {Ljung}, {Greta} {M}.: {Books}},
	url = {https://www.amazon.com/Time-Analysis-Forecasting-Probability-Statistics/dp/1118675029},
	urldate = {2021-01-08}
}

@misc{TianLongWangLuShuDianTimeSeries,
	title = {天瓏網路書店 {\textbar} {Time} {Series} {Analysis}: {Forecasting} and {Control}, 5/e ({Hardcover})},
	shorttitle = {天瓏網路書店 {\textbar} {Time} {Series} {Analysis}},
	url = {https://www.tenlong.com.tw/products/9781118675021},
	abstract = {書名：Time Series Analysis: Forecasting and Control, 5/e (Hardcover)，ISBN：1118675029，作者：George E. P. Box, Gwilym M. Jenkins, Gregory C. Reinsel, Greta M. Ljung，出版社：Wiley，出版日期：2015-06-29},
	language = {zh-Hant-TW},
	urldate = {2021-01-08},
	journal = {天瓏網路書店}
}

@article{zhangNeuralNetworkForecasting2005,
	series = {Decision {Support} {Systems} in the {Internet} {Age}},
	title = {Neural network forecasting for seasonal and trend time series},
	volume = {160},
	issn = {0377-2217},
	url = {http://www.sciencedirect.com/science/article/pii/S0377221703005484},
	doi = {10.1016/j.ejor.2003.08.037},
	abstract = {Neural networks have been widely used as a promising method for time series forecasting. However, limited empirical studies on seasonal time series forecasting with neural networks yield mixed results. While some find that neural networks are able to model seasonality directly and prior deseasonalization is not necessary, others conclude just the opposite. In this paper, we investigate the issue of how to effectively model time series with both seasonal and trend patterns. In particular, we study the effectiveness of data preprocessing, including deseasonalization and detrending, on neural network modeling and forecasting performance. Both simulation and real data are examined and results are compared to those obtained from the Box–Jenkins seasonal autoregressive integrated moving average models. We find that neural networks are not able to capture seasonal or trend variations effectively with the unpreprocessed raw data and either detrending or deseasonalization can dramatically reduce forecasting errors. Moreover, a combined detrending and deseasonalization is found to be the most effective data preprocessing approach.},
	language = {en},
	number = {2},
	urldate = {2021-01-08},
	journal = {European Journal of Operational Research},
	author = {Zhang, G. Peter and Qi, Min},
	month = jan,
	year = {2005},
	keywords = {Seasonality, Forecasting, Box–Jenkins method, Neural networks, Time series},
	pages = {501--514},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\X4DJ8B6S\\Zhang 與 Qi - 2005 - Neural network forecasting for seasonal and trend .pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\QFRRN6LL\\S0377221703005484.html:text/html}
}

@article{zhuClassNoiseVs2004,
	title = {Class {Noise} vs. {Attribute} {Noise}: {A} {Quantitative} {Study}},
	shorttitle = {Class {Noise} vs. {Attribute} {Noise}},
	doi = {10.1007/s10462-004-0751-8},
	abstract = {Real-world data is never perfect and can often suffer from corruptions (noise) that may impact interpretations of the data, models created from the data and decisions made based on the data. Noise can reduce system performance in terms of classification accuracy, time in building a classifier and the size of the classifier. Accordingly, most existing learning algorithms have integrated various approaches to enhance their learning abilities from noisy environments, but the existence of noise can still introduce serious negative impacts. A more reasonable solution might be to employ some preprocessing mechanisms to handle noisy instances before a learner is formed. Unfortunately, rare research has been conducted to systematically explore the impact of noise, especially from the noise handling point of view. This has made various noise processing techniques less significant, specifically when dealing with noise that is introduced in attributes. In this paper, we present a systematic evaluation on the effect of noise in machine learning. Instead of taking any unified theory of noise to evaluate the noise impacts, we differentiate noise into two categories: class noise and attribute noise, and analyze their impacts on the system performance separately. Because class noise has been widely addressed in existing research efforts, we concentrate on attribute noise. We investigate the relationship between attribute noise and classification accuracy, the impact of noise at different attributes, and possible solutions in handling attribute noise. Our conclusions can be used to guide interested readers to enhance data quality by designing various noise handling mechanisms.},
	journal = {Artificial Intelligence Review},
	author = {Zhu, Xingquan and Wu, X.},
	year = {2004}
}

@inproceedings{nairRectifiedLinearUnits2010,
	title = {Rectified {Linear} {Units} {Improve} {Restricted} {Boltzmann} {Machines}},
	abstract = {Restricted Boltzmann machines were developed using binary stochastic hidden units. These can be generalized by replacing each binary unit by an infinite number of copies that all have the same...},
	language = {en},
	urldate = {2021-01-13},
	author = {Nair, Vinod and Hinton, Geoffrey E.},
	month = jan,
	year = {2010},
	file = {Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\B4JYDV5P\\forum.html:text/html;Full Text PDF:C\:\\Users\\ChingChih\\Zotero\\storage\\VQQCDZZU\\Nair 與 Hinton - 2010 - Rectified Linear Units Improve Restricted Boltzman.pdf:application/pdf;Snapshot:C\:\\Users\\ChingChih\\Zotero\\storage\\BESUFZRY\\forum.html:text/html}
}

@misc{zotero-235,
	url = {https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&cad=rja&uact=8&ved=2ahUKEwiiqrSylJjuAhUdK6YKHQviAUsQFjABegQIARAC&url=https%3A%2F%2Fieeexplore.ieee.org%2Fdocument%2F21701&usg=AOvVaw1FWk1TxbR3N-_EGF7ZwgTu},
	urldate = {2021-01-13}
}

@misc{PhonemeRecognitionUsinga,
	title = {Phoneme recognition using time-delay neural networks - {IEEE} {Journals} \& {Magazine}},
	url = {https://ieeexplore.ieee.org/document/21701},
	urldate = {2021-01-13},
	file = {Phoneme recognition using time-delay neural networks - IEEE Journals & Magazine:C\:\\Users\\ChingChih\\Zotero\\storage\\MBSMYNCT\\21701.html:text/html}
}
